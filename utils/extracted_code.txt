**Directory Tree:**
notion-telegram-bot
**config.py**
import os
from dotenv import load_dotenv

load_dotenv() 

# Telegram Bot Token
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")

# OpenAI API Key
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# Google AI API Key
GOOGLE_AI_API_KEY = os.environ.get('GOOGLE_AI_API_KEY')
# Notion API Key
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")

# Notion Database ID
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

# Validate required environment variables
required_vars = [
    "TELEGRAM_BOT_TOKEN",
    "OPENAI_API_KEY",
    "GOOGLE_AI_API_KEY",
    "NOTION_API_KEY",
    "NOTION_DATABASE_ID"
]

for var in required_vars:
    if not locals()[var]:
        raise EnvironmentError(f"{var} is not set in the environment variables.")


**main.py**
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters
from config import TELEGRAM_BOT_TOKEN
from src.transcription import transcribe_audio, handle_audio_message
from src.gemini import process_with_gemini
from src.notion import update_notion_document

# Set up logging
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

async def start(update: Update, context):
    user = update.effective_user
    username = user.first_name if user.first_name else "there"
    await update.message.reply_text(f'ðŸ‘‹ Welcome, {username}! \nSend me an audio message to document your ideas easily in Notion. ðŸŽ™ï¸')

async def handle_audio(update: Update, context):
    user = update.effective_user
    logger.info(f"Received audio message from {user.id}")
    
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    # Send a "processing" message immediately
    processing_message = await update.message.reply_text("â³ Processing your audio... Please wait. â³")

    try:
        # Download and save the audio file
        audio_file = await handle_audio_message(update.message.voice)

        transcript = transcribe_audio(audio_file)

        gemini_output = process_with_gemini(transcript)

        # Update Notion document
        notion_url = update_notion_document(gemini_output)

        # Edit the processing message with the success message
        await processing_message.edit_text(
            f"âœ… **Audio processed successfully!** ðŸŽ‰\n\nYour insights have been documented in Notion: {notion_url} ðŸ“„\n\nHave a productive day! âœ¨"
        )

    except Exception as e:
        logger.error(f"Error processing audio: {str(e)}")
        # Edit the processing message with the error message
        await processing_message.edit_text(
            "âš ï¸ **Oops! An error occurred.** ðŸ˜ž\n\nWe couldn't process your audio. Please try again later. If the problem persists, contact support. ðŸ™" 
        )

def main():
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.VOICE, handle_audio))

    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()

  src
  **notion.py**
from notion_client import Client
from config import NOTION_API_KEY, NOTION_DATABASE_ID

notion = Client(auth=NOTION_API_KEY)

def update_notion_document(content: dict) -> str:
    try:
        if content["type"] == "thought":
            page = notion.pages.create(
                parent={"database_id": NOTION_DATABASE_ID},
                properties={
                "title": [{ "type": "text", "text": { "content": content["title"], "link": None } }]
                },
                children=[
                    {
                        "object": "block",
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{"type": "text", "text": {"content": content["summary"]}}]
                        }
                    }
                ]
            )

        elif content["type"] == "task":
           pass

        else:
            raise ValueError("Invalid content type. Must be 'thought' or 'task'.")

        # Return the URL of the created page
        return f"https://www.notion.so/{page['id'].replace('-', '')}"

    except Exception as e:
        raise Exception(f"Error updating Notion document: {str(e)}")

  **structure.py**
import requests
from collections import deque
import time
import concurrent.futures
import json

# Replace with your Notion integration token
NOTION_TOKEN = "secret_GK4jGTAp26UwRfy1lT55RZwoEQPKsCnqFPnIfqPjJJp"

# Replace with the ID of the page containing the databases
PAGE_ID = "add3e3ebc3ff4ee38974df2b8a31e45f"

NOTION_API_BASE = "https://api.notion.com/v1"
NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

def get_databases_from_block(block_id):
    """Retrieves all databases present within a Notion block (page or database)."""
    databases = []
    has_more = True
    start_cursor = None

    while has_more:
        url = f"{NOTION_API_BASE}/blocks/{block_id}/children"
        params = {"page_size": 100}
        if start_cursor:
            params["start_cursor"] = start_cursor

        response = requests.get(url, headers=NOTION_HEADERS, params=params).json()

        for child in response["results"]:
            if child["type"] == "child_database":
                databases.append(child)
            elif child["type"] == "child_page":
                pass  # We'll handle recursive searches differently

        has_more = response["has_more"]
        start_cursor = response["next_cursor"]

    return databases

def get_database_info(database_id):
    """Retrieves detailed information about a specific database."""
    url = f"{NOTION_API_BASE}/databases/{database_id}"
    response = requests.get(url, headers=NOTION_HEADERS).json()
    
    title = "Untitled"
    if 'title' in response:
        title_items = response['title']
        if title_items and isinstance(title_items, list):
            title = title_items[0].get('plain_text', 'Untitled')
        elif isinstance(title_items, dict):
            title = title_items.get('plain_text', 'Untitled')
    
    description = "No description"
    if 'description' in response:
        desc_items = response['description']
        if desc_items and isinstance(desc_items, list):
            description = desc_items[0].get('plain_text', 'No description')
        elif isinstance(desc_items, str):
            description = desc_items
    
    schema = response.get('properties', {})
    
    return {
        "title": title,
        "id": database_id,
        "description": description,
        "schema": schema
    }

def retrieve_all_pages(database_id):
    """Retrieves all pages from a Notion database, handling pagination."""
    all_pages = []
    has_more = True
    next_cursor = None

    while has_more:
        url = f"{NOTION_API_BASE}/databases/{database_id}/query"
        payload = {"page_size": 100}
        if next_cursor:
            payload["start_cursor"] = next_cursor

        response = requests.post(url, headers=NOTION_HEADERS, json=payload).json()

        if "results" in response:
            all_pages.extend(response["results"])
            has_more = response["has_more"]
            next_cursor = response["next_cursor"]
        else:
            print(f"Error retrieving pages: {response}")
            break

    return all_pages

def process_block(block_id, visited):
    """Process a single block, returning its databases and pages."""
    if block_id in visited:
        return [], []

    visited.add(block_id)
    databases = get_databases_from_block(block_id)
    
    block_databases = []
    pages_list = []

    for database in databases:
        db_info = get_database_info(database['id'])
        block_databases.append(db_info)

        pages = retrieve_all_pages(database['id'])
        for page in pages:
            page_title = next((prop_value['title'][0]['plain_text'] 
                               for prop_name, prop_value in page['properties'].items() 
                               if prop_value['type'] == 'title' and prop_value['title']), "Untitled")
            pages_list.append({
                "title": page_title,
                "id": page['id']
            })

    # Check for pages within regular pages (not databases)
    if not databases:
        url = f"{NOTION_API_BASE}/blocks/{block_id}/children"
        response = requests.get(url, headers=NOTION_HEADERS).json()
        for page in response['results']:
            if page['type'] == 'child_page':
                pages_list.append({
                    "title": page['child_page']['title'],
                    "id": page['id']
                })

    return block_databases, pages_list

def build_database_tree(block_id):
    """Builds a tree structure of databases within a Notion block using parallel processing."""
    queue = deque([block_id])
    visited = set()
    tree = []
    all_pages = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        while queue:
            current_batch = list(queue)
            queue.clear()

            future_to_block = {executor.submit(process_block, block_id, visited): block_id for block_id in current_batch}
            
            for future in concurrent.futures.as_completed(future_to_block):
                block_databases, block_pages = future.result()
                tree.extend(block_databases)
                all_pages.extend(block_pages)
                
                queue.extend([db['id'] for db in block_databases])
                queue.extend([page['id'] for page in block_pages])

    return tree, all_pages

def get_options_string(prop_details):
    """Returns a string of options for select, multi-select, and status properties."""
    options = prop_details.get(prop_details['type'], {}).get('options', [])
    option_names = [option.get('name', '') for option in options]
    return f"[{', '.join(option_names)}]" if option_names else ""

def print_database_info(database, indent=0):
    """Prints detailed information about a database."""
    print("  " * indent + f"- {database['title']} (ID: {database['id']})")
    print("  " * (indent + 2) + f"Description: {database['description']}")
    print("  " * (indent + 2) + "Schema:")
    for prop_name, prop_details in database['schema'].items():
        prop_type = prop_details['type']
        options_string = ""
        if prop_type in ['select', 'multi_select', 'status']:
            options_string = get_options_string(prop_details)
        print("  " * (indent + 4) + f"{prop_name}: {prop_type} {options_string}")

if __name__ == "__main__":
    start_time = time.time()

    database_tree, pages_list = build_database_tree(PAGE_ID)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print("Database Tree with Extended Info:")
    for db in database_tree:
        print_database_info(db)

    print(f"\nScript execution time: {elapsed_time:.4f} seconds")

  **transcription.py**
import os
from telegram import Voice
import aiohttp
import aiofiles
from openai import OpenAI
from config import OPENAI_API_KEY

client = OpenAI(base_url="https://api.groq.com/openai/v1",
    api_key=OPENAI_API_KEY)

async def handle_audio_message(voice: Voice) -> str:
    """
    Download and save the audio file from a Telegram voice message.
    
    :param voice: Voice object from the Telegram message
    :return: Path to the saved audio file
    """
    file_id = voice.file_id
    file = await voice.get_file()
    file_path = file.file_path
    
    # Create a temporary directory for audio files if it doesn't exist
    os.makedirs("temp_audio", exist_ok=True)
    
    local_filename = os.path.join("temp_audio", f"{file_id}.ogg")
    
    async with aiohttp.ClientSession() as session:
        async with session.get(file_path) as resp:
            if resp.status == 200:
                async with aiofiles.open(local_filename, mode='wb') as f:
                    await f.write(await resp.read())
    
    return local_filename


def transcribe_audio(audio_file_path: str) -> str:
    """
    Transcribe the audio file using OpenAI's Whisper API.
    
    :param audio_file_path: Path to the audio file
    :return: Transcribed text
    """
    try:
        with open(audio_file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3", 
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        raise Exception(f"Error transcribing audio: {str(e)}")
    finally:
        # Clean up the temporary audio file
        os.remove(audio_file_path)

  **gemini.py**
import google.generativeai as genai
import json
from config import GOOGLE_AI_API_KEY

genai.configure(api_key=GOOGLE_AI_API_KEY)

def process_with_gemini(transcript: str) -> dict:
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-exp-0827')
        
        with open('src/meta_prompt.txt', 'r') as file:
            prompt = file.read()
        prompt += transcript
        
        response = model.generate_content(prompt)
        print(response.text)
        
        try:
            # Attempt to parse the response as JSON
            json_response = json.loads(response.text)
            return json_response
        except json.JSONDecodeError:
            raise ValueError("Gemini response is not valid JSON.")
    
    except Exception as e:
        raise Exception(f"Error processing with Gemini: {str(e)}")

  .idx
**Directory Tree:**
notion-telegram-bot
**config.py**
import os
from dotenv import load_dotenv

load_dotenv() 

# Telegram Bot Token
TELEGRAM_BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN")

# OpenAI API Key
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")

# Google AI API Key
GOOGLE_AI_API_KEY = os.environ.get('GOOGLE_AI_API_KEY')
# Notion API Key
NOTION_API_KEY = os.environ.get("NOTION_API_KEY")

# Notion Database ID
NOTION_DATABASE_ID = os.environ.get("NOTION_DATABASE_ID")

# Validate required environment variables
required_vars = [
    "TELEGRAM_BOT_TOKEN",
    "OPENAI_API_KEY",
    "GOOGLE_AI_API_KEY",
    "NOTION_API_KEY",
    "NOTION_DATABASE_ID"
]

for var in required_vars:
    if not locals()[var]:
        raise EnvironmentError(f"{var} is not set in the environment variables.")


**main.py**
import logging
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters
from config import TELEGRAM_BOT_TOKEN
from src.transcription import transcribe_audio, handle_audio_message
from src.gemini import process_with_gemini
from src.notion import update_notion_document

# Set up logging
logging.basicConfig(format='%(asctime)s - %(name)s - %(levelname)s - %(message)s', level=logging.INFO)
logger = logging.getLogger(__name__)

async def start(update: Update, context):
    user = update.effective_user
    username = user.first_name if user.first_name else "there"
    await update.message.reply_text(f'ðŸ‘‹ Welcome, {username}! \nSend me an audio message to document your ideas easily in Notion. ðŸŽ™ï¸')

async def handle_audio(update: Update, context):
    user = update.effective_user
    logger.info(f"Received audio message from {user.id}")
    
    await context.bot.send_chat_action(chat_id=update.effective_chat.id, action="typing")

    # Send a "processing" message immediately
    processing_message = await update.message.reply_text("â³ Processing your audio... Please wait. â³")

    try:
        # Download and save the audio file
        audio_file = await handle_audio_message(update.message.voice)

        transcript = transcribe_audio(audio_file)

        gemini_output = process_with_gemini(transcript)

        # Update Notion document
        notion_url = update_notion_document(gemini_output)

        # Edit the processing message with the success message
        await processing_message.edit_text(
            f"âœ… **Audio processed successfully!** ðŸŽ‰\n\nYour insights have been documented in Notion: {notion_url} ðŸ“„\n\nHave a productive day! âœ¨"
        )

    except Exception as e:
        logger.error(f"Error processing audio: {str(e)}")
        # Edit the processing message with the error message
        await processing_message.edit_text(
            "âš ï¸ **Oops! An error occurred.** ðŸ˜ž\n\nWe couldn't process your audio. Please try again later. If the problem persists, contact support. ðŸ™" 
        )

def main():
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()

    application.add_handler(CommandHandler("start", start))
    application.add_handler(MessageHandler(filters.VOICE, handle_audio))

    application.run_polling(allowed_updates=Update.ALL_TYPES)

if __name__ == '__main__':
    main()

  src
  **notion.py**
from notion_client import Client
from config import NOTION_API_KEY, NOTION_DATABASE_ID

notion = Client(auth=NOTION_API_KEY)

def update_notion_document(content: dict) -> str:
    try:
        if content["type"] == "thought":
            page = notion.pages.create(
                parent={"database_id": NOTION_DATABASE_ID},
                properties={
                "title": [{ "type": "text", "text": { "content": content["title"], "link": None } }]
                },
                children=[
                    {
                        "object": "block",
                        "type": "paragraph",
                        "paragraph": {
                            "rich_text": [{"type": "text", "text": {"content": content["summary"]}}]
                        }
                    }
                ]
            )

        elif content["type"] == "task":
           pass

        else:
            raise ValueError("Invalid content type. Must be 'thought' or 'task'.")

        # Return the URL of the created page
        return f"https://www.notion.so/{page['id'].replace('-', '')}"

    except Exception as e:
        raise Exception(f"Error updating Notion document: {str(e)}")

  **structure.py**
import requests
from collections import deque
import time
import concurrent.futures
import json

# Replace with your Notion integration token
NOTION_TOKEN = "secret_GK4jGTAp26UwRfy1lT55RZwoEQPKsCnqFPnIfqPjJJp"

# Replace with the ID of the page containing the databases
PAGE_ID = "add3e3ebc3ff4ee38974df2b8a31e45f"

NOTION_API_BASE = "https://api.notion.com/v1"
NOTION_HEADERS = {
    "Authorization": f"Bearer {NOTION_TOKEN}",
    "Content-Type": "application/json",
    "Notion-Version": "2022-06-28"
}

def get_databases_from_block(block_id):
    """Retrieves all databases present within a Notion block (page or database)."""
    databases = []
    has_more = True
    start_cursor = None

    while has_more:
        url = f"{NOTION_API_BASE}/blocks/{block_id}/children"
        params = {"page_size": 100}
        if start_cursor:
            params["start_cursor"] = start_cursor

        response = requests.get(url, headers=NOTION_HEADERS, params=params).json()

        for child in response["results"]:
            if child["type"] == "child_database":
                databases.append(child)
            elif child["type"] == "child_page":
                pass  # We'll handle recursive searches differently

        has_more = response["has_more"]
        start_cursor = response["next_cursor"]

    return databases

def get_database_info(database_id):
    """Retrieves detailed information about a specific database."""
    url = f"{NOTION_API_BASE}/databases/{database_id}"
    response = requests.get(url, headers=NOTION_HEADERS).json()
    
    title = "Untitled"
    if 'title' in response:
        title_items = response['title']
        if title_items and isinstance(title_items, list):
            title = title_items[0].get('plain_text', 'Untitled')
        elif isinstance(title_items, dict):
            title = title_items.get('plain_text', 'Untitled')
    
    description = "No description"
    if 'description' in response:
        desc_items = response['description']
        if desc_items and isinstance(desc_items, list):
            description = desc_items[0].get('plain_text', 'No description')
        elif isinstance(desc_items, str):
            description = desc_items
    
    schema = response.get('properties', {})
    
    return {
        "title": title,
        "id": database_id,
        "description": description,
        "schema": schema
    }

def retrieve_all_pages(database_id):
    """Retrieves all pages from a Notion database, handling pagination."""
    all_pages = []
    has_more = True
    next_cursor = None

    while has_more:
        url = f"{NOTION_API_BASE}/databases/{database_id}/query"
        payload = {"page_size": 100}
        if next_cursor:
            payload["start_cursor"] = next_cursor

        response = requests.post(url, headers=NOTION_HEADERS, json=payload).json()

        if "results" in response:
            all_pages.extend(response["results"])
            has_more = response["has_more"]
            next_cursor = response["next_cursor"]
        else:
            print(f"Error retrieving pages: {response}")
            break

    return all_pages

def process_block(block_id, visited):
    """Process a single block, returning its databases and pages."""
    if block_id in visited:
        return [], []

    visited.add(block_id)
    databases = get_databases_from_block(block_id)
    
    block_databases = []
    pages_list = []

    for database in databases:
        db_info = get_database_info(database['id'])
        block_databases.append(db_info)

        pages = retrieve_all_pages(database['id'])
        for page in pages:
            page_title = next((prop_value['title'][0]['plain_text'] 
                               for prop_name, prop_value in page['properties'].items() 
                               if prop_value['type'] == 'title' and prop_value['title']), "Untitled")
            pages_list.append({
                "title": page_title,
                "id": page['id']
            })

    # Check for pages within regular pages (not databases)
    if not databases:
        url = f"{NOTION_API_BASE}/blocks/{block_id}/children"
        response = requests.get(url, headers=NOTION_HEADERS).json()
        for page in response['results']:
            if page['type'] == 'child_page':
                pages_list.append({
                    "title": page['child_page']['title'],
                    "id": page['id']
                })

    return block_databases, pages_list

def build_database_tree(block_id):
    """Builds a tree structure of databases within a Notion block using parallel processing."""
    queue = deque([block_id])
    visited = set()
    tree = []
    all_pages = []

    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
        while queue:
            current_batch = list(queue)
            queue.clear()

            future_to_block = {executor.submit(process_block, block_id, visited): block_id for block_id in current_batch}
            
            for future in concurrent.futures.as_completed(future_to_block):
                block_databases, block_pages = future.result()
                tree.extend(block_databases)
                all_pages.extend(block_pages)
                
                queue.extend([db['id'] for db in block_databases])
                queue.extend([page['id'] for page in block_pages])

    return tree, all_pages

def get_options_string(prop_details):
    """Returns a string of options for select, multi-select, and status properties."""
    options = prop_details.get(prop_details['type'], {}).get('options', [])
    option_names = [option.get('name', '') for option in options]
    return f"[{', '.join(option_names)}]" if option_names else ""

def print_database_info(database, indent=0):
    """Prints detailed information about a database."""
    print("  " * indent + f"- {database['title']} (ID: {database['id']})")
    print("  " * (indent + 2) + f"Description: {database['description']}")
    print("  " * (indent + 2) + "Schema:")
    for prop_name, prop_details in database['schema'].items():
        prop_type = prop_details['type']
        options_string = ""
        if prop_type in ['select', 'multi_select', 'status']:
            options_string = get_options_string(prop_details)
        print("  " * (indent + 4) + f"{prop_name}: {prop_type} {options_string}")

if __name__ == "__main__":
    start_time = time.time()

    database_tree, pages_list = build_database_tree(PAGE_ID)

    end_time = time.time()
    elapsed_time = end_time - start_time

    print("Database Tree with Extended Info:")
    for db in database_tree:
        print_database_info(db)

    print(f"\nScript execution time: {elapsed_time:.4f} seconds")

  **transcription.py**
import os
from telegram import Voice
import aiohttp
import aiofiles
from openai import OpenAI
from config import OPENAI_API_KEY

client = OpenAI(base_url="https://api.groq.com/openai/v1",
    api_key=OPENAI_API_KEY)

async def handle_audio_message(voice: Voice) -> str:
    """
    Download and save the audio file from a Telegram voice message.
    
    :param voice: Voice object from the Telegram message
    :return: Path to the saved audio file
    """
    file_id = voice.file_id
    file = await voice.get_file()
    file_path = file.file_path
    
    # Create a temporary directory for audio files if it doesn't exist
    os.makedirs("temp_audio", exist_ok=True)
    
    local_filename = os.path.join("temp_audio", f"{file_id}.ogg")
    
    async with aiohttp.ClientSession() as session:
        async with session.get(file_path) as resp:
            if resp.status == 200:
                async with aiofiles.open(local_filename, mode='wb') as f:
                    await f.write(await resp.read())
    
    return local_filename


def transcribe_audio(audio_file_path: str) -> str:
    """
    Transcribe the audio file using OpenAI's Whisper API.
    
    :param audio_file_path: Path to the audio file
    :return: Transcribed text
    """
    try:
        with open(audio_file_path, "rb") as audio_file:
            transcript = client.audio.transcriptions.create(
                model="whisper-large-v3", 
                file=audio_file
            )
        return transcript.text
    except Exception as e:
        raise Exception(f"Error transcribing audio: {str(e)}")
    finally:
        # Clean up the temporary audio file
        os.remove(audio_file_path)

  **gemini.py**
import google.generativeai as genai
import json
from config import GOOGLE_AI_API_KEY

genai.configure(api_key=GOOGLE_AI_API_KEY)

def process_with_gemini(transcript: str) -> dict:
    try:
        model = genai.GenerativeModel('gemini-1.5-flash-exp-0827')
        
        with open('src/meta_prompt.txt', 'r') as file:
            prompt = file.read()
        prompt += transcript
        
        response = model.generate_content(prompt)
        print(response.text)
        
        try:
            # Attempt to parse the response as JSON
            json_response = json.loads(response.text)
            return json_response
        except json.JSONDecodeError:
            raise ValueError("Gemini response is not valid JSON.")
    
    except Exception as e:
        raise Exception(f"Error processing with Gemini: {str(e)}")

  .idx
